2025-08-07

- Add `executor` MCP tool to run LLM-generated TS safely via Deno.
  - New: `src/services/executor/ExecutorMCPTool.ts`
  - New: `electron/executor/sandbox_runner.ts`
  - Updated: `electron/mcp-manager.ts` to register `executor` server, expose `run_ts` tool, and list it among built-ins.
  - Updated backend prompts (`apps/workflow-engine/src/routes/chat.ts`, `chat-v2.ts`) to advertise `executor/run_ts` so LLM can select it.

- Add "Code Run" toggle in chat header and request plumb:
  - Updated: `components/ChatHeader.tsx` adds a Code Run button and props.
  - Updated: `components/ChatInterface.tsx` manages `forceExecutor` state and passes it to chat adapter.
  - Updated: `hooks/useChatAdapter.ts` accepts `forceExecutor` and sends it to `/api/v2/chat/stream`.
  - Updated: `apps/workflow-engine/src/routes/chat-v2.ts` accepts `forceExecutor`, biases tool selection, and returns `savedFiles` for executor readPaths augmentation.

Impact: Enables AI to generate and execute code with ExcelJS without external MCP servers. Adds a safe, permissioned execution path and integrates outputs back into chat/tool results.

2025-08-08

- Add mock-response detection and UI indicator:
  - Updated backend `LLMService.chatWithSystem` to return `{ isMock }` and to set `isMock: true` when Anthropic API key missing or non-Anthropic provider selected.
  - Updated endpoints to propagate mock flag:
    - `apps/workflow-engine/src/routes/chat-v2.ts` now includes `isMock` in SSE `complete` event and JSON response.
    - `apps/workflow-engine/src/routes/chat.ts` now includes `isMock` in JSON response.
  - Updated client to surface mock status:
    - `hooks/useChatAdapter.ts` now stores `isMock` on the assistant message for both streaming and non-streaming paths.
    - `services/chatHistoryService.ts` extended `ChatMessage` with `isMock?: boolean`.
    - `components/MessageRenderer.tsx` renders a "Mock response" badge on assistant messages when `isMock` is true.
    - `components/ChatMessageList.tsx` passes `isMock` to `MessageRenderer`.

Effect: When the server falls back to mock responses (e.g., missing `ANTHROPIC_API_KEY` or unsupported provider like `openai`/`bedrock`), the UI clearly indicates the response is mocked. This helps diagnose why different model selections appear to "not work" and ensures clarity while testing endpoints.
